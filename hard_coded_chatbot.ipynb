{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sof=pd.read_csv(\"df_python_stackoverflow .csv\")#.drop(columns='Unnamed: 0')\n",
    "# reddit=pd.read_csv(\"df_python_reddit.csv\")#[[\"question\",\"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # concate two dataframes \n",
    "# df=pd.concat([sof,reddit]).drop(columns='Unnamed: 0')\n",
    "# df=df.dropna(axis=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>statistics analysis definition</td>\n",
       "      <td>Statistical analysis is the science of collect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is normal distribution</td>\n",
       "      <td>In probability theory, a normal (or Gaussian o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Definition of statistical distributions</td>\n",
       "      <td>A statistical distribution is a representation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Examples of Discrete Distributions</td>\n",
       "      <td>The Bernoulli Distribution\\nThe Bernoulli dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Examples of Continuous Distributions</td>\n",
       "      <td>A normal distribution is the single most impor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question  \\\n",
       "0           statistics analysis definition   \n",
       "1              what is normal distribution   \n",
       "2  Definition of statistical distributions   \n",
       "3      Examples of Discrete Distributions    \n",
       "4     Examples of Continuous Distributions   \n",
       "\n",
       "                                              answer  \n",
       "0  Statistical analysis is the science of collect...  \n",
       "1  In probability theory, a normal (or Gaussian o...  \n",
       "2  A statistical distribution is a representation...  \n",
       "3  The Bernoulli Distribution\\nThe Bernoulli dist...  \n",
       "4  A normal distribution is the single most impor...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"small_sample.csv\")[['question','answer']].dropna(axis=0).reset_index().drop(columns='index')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r'[-()\\\"#/@;:<>{}`+=~|.!?,]\\|', \"\", text)\n",
    "    text=text.replace(\"[\\'\",\"\").replace(\"\\n\",\" \").replace(\"']\",\" \").replace('[\"',\"\").replace('\"]',\"\").replace(\"it\\'s\",\"it's \").replace(\"\\', \\'\",\"\")\n",
    "    text=text.replace(\"\\',\",\"\").replace(\"it\\'s\",\"it is \").replace(\"it\\\\\\'s\",\"it is\").replace(\" \\\\\",\" \")\n",
    "    text=text.replace('\",',\" \").replace(\"\\',\",\"\").replace( \":\\',\",\"\").replace(\"here\\'s\",\"\").replace(\":\",\"\").replace(',\"',\"\")\n",
    "    text=text.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\'s\",\"'s\")\n",
    "    text=re.sub(r\"let's\", \"let us\", text)\n",
    "    text = text.replace(\"\\'s\", \"\")\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#declare answers and questions\n",
    "questions=df.question\n",
    "answers=df.answer\n",
    "# Cleaning the questions\n",
    "clean_questions = []\n",
    "for question in questions:\n",
    "    clean_questions.append(clean_text(question))\n",
    "# Cleaning the answers\n",
    "clean_answers = []\n",
    "for answer in answers:\n",
    "    clean_answers.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statistics analysis definition',\n",
       " 'what is normal distribution',\n",
       " 'definition of statistical distributions',\n",
       " 'examples of discrete distributions ',\n",
       " 'examples of continuous distributions',\n",
       " 'what is a probability mass function (pmf)?',\n",
       " 'definition of  continuous variables',\n",
       " 'what are continuous variables',\n",
       " 'definition of discrete variable',\n",
       " 'what is a discrete variable']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_questions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list contains  punctuation\n",
    "sw_list = stopwords.words('english')\n",
    "sw_list += list(string.punctuation)\n",
    "sw_list += [\"''\", '\"\"', '...', '``', '’', '“', '’', '”', '‘', '‘',\"'\", '©',\n",
    "'said',\"'s\", \"also\",'one',\"n't\",'com', 'satirewire', '-', '–','--' ,\n",
    "'—', '_','satirewire.com']\n",
    "sw_set = set(sw_list)\n",
    "\n",
    "# tokenization\n",
    "def process_data(string):\n",
    "    tokens = nltk.word_tokenize(string) # tokenization\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in sw_set]# stop workds removal\n",
    "    return stopwords_removed\n",
    "\n",
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "# create a function stemming() and loop through each word in a review\n",
    "def stemming(string):\n",
    "    stemmed_string=[]\n",
    "    for w in string:\n",
    "        stemmed_string.append(ps.stem(w))\n",
    "    return stemmed_string\n",
    "\n",
    "# import libraries\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# create a function  and loop through each word in  a review\n",
    "def lemmatization(string):\n",
    "    lemma_list=[]\n",
    "    for word in string:\n",
    "        lemma_word=lemmatizer.lemmatize(word,pos='v') \n",
    "        lemma_list.append(lemma_word)\n",
    "    return lemma_list\n",
    "\n",
    "# Conbime all functions above and obtian cleaned text data \n",
    "def data_preprocessing(text_data):\n",
    "    #tokenization, stop words removal, punctuation marks removel\n",
    "    processed_string=list(map(process_data,text_data))\n",
    "    # stemming\n",
    "    stemming_string=list(map(stemming,processed_string))\n",
    "    # lemmatization\n",
    "    lemma_string=list(map(lemmatization,stemming_string))\n",
    "    \n",
    "    return lemma_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_questions=data_preprocessing(clean_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============# Hi There my name is Chacha. Let's Talk #=============\n",
      "You: normal distribution\n",
      "Chacha: In probability theory, a normal (or Gaussian or Gauss or Laplace–Gauss) distribution is a type of continuous probability distribution for a real-valued random variable.  Source: https://en.wikipedia.org/wiki/Normal_distribution\n",
      "\n",
      "You: statistical Analysis\n",
      "Chacha: Statistical analysis is the science of collecting data and uncovering patterns and trends. It’s really just another way of saying “statistics.” After collecting data you can analyze it to:\n",
      "Summarize the data. For example, make a pie chart.\n",
      "Find key measures of location. For example, the mean tells you what the average (or “middling”) number is in a set of data.\n",
      "Calculate measures of spread: these tell you if your data is tightly clustered or more spread out. The standard deviation is one of the more commonly used measures of spread; it tells you how spread out your data is about the mean.\n",
      "Make future predictions based on past behavior. This is especially useful in retail, manufacturing, banking, sports or for any organization where knowing future trends would be a benefit.\n",
      "Test an experiment’s hypothesis. Collecting data from an experiment only tells a story when you analyze the data. This part of statistical analysis is more formally called “Hypothesis Testing,” where the null hypothesis (the commonly accepted theory) is either proved or disproved. For more information please visit: https://www.statisticshowto.com/statistical-analysis/\n",
      "You: distribution \n",
      "Chacha: In probability theory, a normal (or Gaussian or Gauss or Laplace–Gauss) distribution is a type of continuous probability distribution for a real-valued random variable.  Source: https://en.wikipedia.org/wiki/Normal_distribution\n",
      "\n",
      "Chacha: In probability theory, a normal (or Gaussian or Gauss or Laplace–Gauss) distribution is a type of continuous probability distribution for a real-valued random variable.  Source: https://en.wikipedia.org/wiki/Normal_distribution\n",
      "\n",
      "Chacha: In probability theory, a normal (or Gaussian or Gauss or Laplace–Gauss) distribution is a type of continuous probability distribution for a real-valued random variable.  Source: https://en.wikipedia.org/wiki/Normal_distribution\n",
      "\n",
      "Chacha: The Bernoulli Distribution\n",
      "The Bernoulli distribution represents the probability of success for a certain experiment (the outcome being \"success or not\", so there are two possible outcomes). A coin toss is a classic example of a Bernoulli experiment with a probability of success 0.5 or 50%, but a Bernoulli experiment can have any probability of success between 0 and 1.\n",
      "\n",
      "The Poisson Distribution\n",
      "The Poisson distribution represents the probability of  𝑛  events in a given time period when the overall rate of occurrence is constant. A typical example is pieces of mail. If your overall mail received is constant, the number of items received on a single day (or month) follows a Poisson distribution. Other examples might include visitors to a website, or customers arriving at a store, or clients waiting to be served in a queue.\n",
      "\n",
      "The Uniform Distribution\n",
      "The uniform distribution occurs when all possible outcomes are equally likely. The dice example shown before follows a uniform distribution with equal probabilities for throwing values from 1 to 6. \n",
      "Chacha: A statistical distribution is a representation of the frequencies of potential events or the percentage of time each event occurs.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(\"=============# Hi There my name is Chacha. Let's Talk #=============\")\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    \n",
    "    question = input(\"You: \")\n",
    "    if question == 'Goodbye':\n",
    "        print(\"Bye\")\n",
    "        break    \n",
    "    # NLP\n",
    "    processed_question=process_data(question)\n",
    "    stemming_question=stemming(processed_question)\n",
    "    lemma_question=lemmatization(stemming_question)\n",
    "    # to find which row has intersection with the words from question you asked\n",
    "    # which means to find the who have common elements between your question and the data\n",
    "    inter_list=[]\n",
    "    for i in cleaned_questions:\n",
    "        if (set(lemma_question) & set(i)):\n",
    "            inter_list.append((list(set(lemma_question) & set(i)),cleaned_questions.index(i)))\n",
    "    # find the max length of common elements\n",
    "    lengths=[len(inter_list[i][0]) for i in range(len(inter_list)) ]\n",
    "    indexes=[]\n",
    "    if len(lengths)>0:\n",
    "        # find all the index whose correspondiong question data have the most common elements\n",
    "        for i in range(len(inter_list)):\n",
    "            if len(inter_list[i][0])==max(lengths):\n",
    "                indexes.append(inter_list[i][1])  \n",
    "             # to randomly find an answer based on the index\n",
    "                answer_index=random.choice(indexes)\n",
    "                print(\"Chacha: \"+ answers[answer_index])\n",
    "    else:\n",
    "        print(\"Sorry, I don't know. I need to learn more!\")\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
