{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"chatbot_data_Q&A - basic_python_questions.csv\").dropna(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>definition of data visualization, what is data...</td>\n",
       "      <td>After deriving the required results from a sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>What Tools do Professional Data Scientists Use?\\n</td>\n",
       "      <td>Python - There are many languages that can be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Mian tools in data science</td>\n",
       "      <td>Python - There are many languages that can be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>How to install git</td>\n",
       "      <td>Git insallation on Windows: https://www.youtub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>What is Conda and Anaconda?</td>\n",
       "      <td>Anaconda is a free and open-source[6] distribu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "124  definition of data visualization, what is data...   \n",
       "125  What Tools do Professional Data Scientists Use?\\n   \n",
       "126                         Mian tools in data science   \n",
       "127                                 How to install git   \n",
       "128                        What is Conda and Anaconda?   \n",
       "\n",
       "                                                answer  \n",
       "124  After deriving the required results from a sta...  \n",
       "125  Python - There are many languages that can be ...  \n",
       "126  Python - There are many languages that can be ...  \n",
       "127  Git insallation on Windows: https://www.youtub...  \n",
       "128  Anaconda is a free and open-source[6] distribu...  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    0\n",
       "answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some uncompleted questions\n",
    "questions=[]\n",
    "for i in df.question:\n",
    "    if i[-1]==\":\":\n",
    "        questions.append(None)\n",
    "    else:\n",
    "        questions.append(i)\n",
    "        \n",
    "        \n",
    "# remove some uncompleted answers\n",
    "answers=[]\n",
    "for i in df.answer:\n",
    "    if i[-1]==\":\":\n",
    "        answers.append(None)\n",
    "    else:\n",
    "        answers.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange a little bit\n",
    "df['answer']=answers\n",
    "df['question']=questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data?</td>\n",
       "      <td>Based on the definition from google : facts an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is data science?</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data science</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is big data?</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>definition of big data</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  question                                             answer\n",
       "0                    data?  Based on the definition from google : facts an...\n",
       "1    what is data science?  Data science is an inter-disciplinary field th...\n",
       "2             data science  Data science is an inter-disciplinary field th...\n",
       "3        what is big data?  In the data science domain, big data usually r...\n",
       "4  definition of big data   In the data science domain, big data usually r..."
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna(axis=0).copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r'[-()\\\"#/@;:<>{}`+=~|.!?,]\\|', \"\", text)\n",
    "    text=text.replace(\"[\\'\",\"\").replace(\"\\n\",\" \").replace(\"']\",\" \").replace('[\"',\"\").replace('\"]',\"\").replace(\"it\\'s\",\"it's \").replace(\"\\', \\'\",\"\")\n",
    "    text=text.replace(\"\\',\",\"\").replace(\"it\\'s\",\"it is \").replace(\"it\\\\\\'s\",\"it is\").replace(\" \\\\\",\" \")\n",
    "    text=text.replace('\",',\" \").replace(\"\\',\",\"\").replace( \":\\',\",\"\").replace(\"here\\'s\",\"\").replace(\":\",\"\").replace(',\"',\"\")\n",
    "    text=text.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\'s\",\"'s\")\n",
    "    text=re.sub(r\"let's\", \"let us\", text)\n",
    "    text = text.replace(\"\\'s\", \"\")\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#declare answers and questions\n",
    "questions=df.question\n",
    "answers=df.answer\n",
    "# Cleaning the questions\n",
    "clean_questions = []\n",
    "for question in questions:\n",
    "    clean_questions.append(clean_text(question))\n",
    "# Cleaning the answers\n",
    "clean_answers = []\n",
    "for answer in answers:\n",
    "    clean_answers.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['definition of data visualization, what is data visualization?',\n",
       " 'what tools do professional data scientists use? ',\n",
       " 'mian tools in data science',\n",
       " 'how to install git',\n",
       " 'what is conda and anaconda?']"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_questions[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list contains  punctuation\n",
    "#sw_list = stopwords.words('english')\n",
    "sw_list = list(string.punctuation)\n",
    "sw_list += [\"''\", '\"\"', '...', '``', '’', '“', '’', '”', '‘', '‘',\"'\", '©',\n",
    "'said',\"'s\", \"also\",'one',\"n't\",'com', '-', '–','--' ,\n",
    "'—', '_']\n",
    "sw_set = set(sw_list)\n",
    "\n",
    "# tokenization\n",
    "def process_data(string):\n",
    "    tokens = nltk.word_tokenize(string) # tokenization\n",
    "    punctuation_removed = [token.lower() for token in tokens if token.lower() not in sw_set]\n",
    "    return punctuation_removed\n",
    "\n",
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "# create a function stemming() and loop through each word in a review\n",
    "def stemming(string):\n",
    "    stemmed_string=[]\n",
    "    for w in string:\n",
    "        stemmed_string.append(ps.stem(w))\n",
    "    return stemmed_string\n",
    "\n",
    "# import libraries\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# create a function  and loop through each word in  a review\n",
    "def lemmatization(string):\n",
    "    lemma_list=[]\n",
    "    for word in string:\n",
    "        lemma_word=lemmatizer.lemmatize(word,pos='v') \n",
    "        lemma_list.append(lemma_word)\n",
    "    return lemma_list\n",
    "\n",
    "# Conbime all functions above and obtian cleaned text data \n",
    "def data_preprocessing(text_data):\n",
    "    #tokenization, stop words removal, punctuation marks removel\n",
    "    processed_string=list(map(process_data,text_data))\n",
    "    # stemming\n",
    "    stemming_string=list(map(stemming,processed_string))\n",
    "    # lemmatization\n",
    "    lemma_string=list(map(lemmatization,stemming_string))\n",
    "    \n",
    "    return lemma_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_questions=data_preprocessing(clean_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['definit', 'of', 'data', 'visual', 'what', 'be', 'data', 'visual'], ['what', 'tool', 'do', 'profession', 'data', 'scientist', 'use'], ['mian', 'tool', 'in', 'data', 'scienc'], ['how', 'to', 'instal', 'git'], ['what', 'be', 'conda', 'and', 'anaconda']]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_questions[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP(text):\n",
    "    cleaned_question=clean_text(text)\n",
    "    processed_question=process_data(cleaned_question)\n",
    "    stemming_question=stemming(processed_question)\n",
    "    lemma_question=lemmatization(stemming_question)\n",
    "    return lemma_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Greeting \n",
    "greeting=['hey', 'hi', 'hello', 'hey man', 'hi how are you', 'how are you','how is it going', \n",
    "          'nice to meet you', 'how are you doing', 'what is up', 'what is new', \n",
    "          'what is going on', 'how is everything', 'how are things', 'how is life', \n",
    "          'how is your day', 'how is your day going', 'good to see you', 'nice to see you']\n",
    "goodbye=[\"see you\",\"bye\",\"byebye\",\"goodbye\"]\n",
    "\n",
    "thankyou=[\"thanks\",\"thank you\", \"thank you very much\"]\n",
    "yourwelcome=[\"you are welcome ^.^\",\"my pleasure!\",\"I am happy to help you!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============# Hi There my name is Chacha. Let's Talk #=============\n",
      "You: hi\n",
      "Chacha: Hey man\n",
      "\n",
      "You: how are you\n",
      "Chacha: How are things\n",
      "\n",
      "You: what is numpy\n",
      "... ...\n",
      "Chacha: NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more. For more information please visit : https://numpy.org/doc/stable/user/whatisnumpy.html\n",
      "\n",
      "You: what is matplotlib\n",
      "... ...\n",
      "Chacha: Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. From Matplotlib offical website.\n",
      "\n",
      "You: tell me about normal distribution?\n",
      "... ...\n",
      "Chacha: The normal distribution is the most important probability distribution in statistics because it fits many natural phenomena. For example, heights, blood pressure, measurement error, and IQ scores follow the normal distribution. It is also known as the Gaussian distribution and the bell curve.\n",
      "\n",
      "You: how to plot bar chart with matplotlib?\n",
      "... ...\n",
      "Chacha: # if there is a catogorical variable and you want to know their distribution :\n",
      "df['col'].value_counts().plot(kind='bar',color='r')\n",
      "# or you also can do \n",
      "df['col'].value_counts().plot(kind='hist',color='r')\n",
      "\n",
      "You: bar chart with seaborn?\n",
      "... ...\n",
      "Chacha: # if there is a catogorical variable and you want to know their distribution :\n",
      "df['col'].value_counts().plot(kind='bar',color='r')\n",
      "# or you also can do \n",
      "df['col'].value_counts().plot(kind='hist',color='r')\n",
      "\n",
      "You: what is seaborn\n",
      "... ...\n",
      "Chacha: Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. For more information please visti offical website.\n",
      "\n",
      "You: how to select a column from a dataframe\n",
      "... ...\n",
      "Chacha: # if you want to select a specific column you can use this code:\n",
      "df[\"column_name\"] \n",
      "\n",
      "You: how to select a row from a dataframe\n",
      "... ...\n",
      "Chacha: .iloc, which is a Pandas DataFrame indexer used for integer-location based indexing / selection by position\n",
      "\n",
      "df.iloc[3] # select 4th row\n",
      ">>>\n",
      "alcohol                           14.37\n",
      "malic_acid                         1.95\n",
      "ash                                2.50\n",
      "alcalinity_of_ash                 16.80\n",
      "magnesium                        113.00\n",
      "total_phenols                      3.85\n",
      "flavanoids                         3.49\n",
      "nonflavanoid_phenols               0.24\n",
      "proanthocyanins                    2.18\n",
      "color_intensity                    7.80\n",
      "hue                                0.86\n",
      "od280/od315_of_diluted_wines       3.45\n",
      "proline                         1480.00\n",
      "Name: 3, dtype: float64\n",
      "# You can use a colon to select several rows. Note that you'll use a structure .iloc[a:b] where the row with index a will be included in the selection and the row with index b is excluded.\n",
      "df.iloc[5:8]\n",
      "\n",
      "You: how to make a pivot table using pandas\n",
      "... ...\n",
      "Chacha: # code and parameter\n",
      "pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False)\n",
      "\n",
      "# Examples\n",
      "import pandas as pd\n",
      "df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      "                         \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      "                   \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      "                         \"one\", \"one\", \"two\", \"two\"],\n",
      "                   \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      "                         \"small\", \"large\", \"small\", \"small\",\n",
      "                         \"large\"],\n",
      "                   \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      "                   \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      "df\n",
      ">>>\n",
      "     A    B      C  D  E\n",
      "0  foo  one  small  1  2\n",
      "1  foo  one  large  2  4\n",
      "2  foo  one  large  2  5\n",
      "3  foo  two  small  3  5\n",
      "4  foo  two  small  3  6\n",
      "5  bar  one  large  4  6\n",
      "6  bar  one  small  5  8\n",
      "7  bar  two  small  6  9\n",
      "8  bar  two  large  7  9\n",
      "\n",
      "#This first example aggregates values by taking the sum.\n",
      "\n",
      "table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "                    columns=['C'], aggfunc=np.sum)\n",
      "table\n",
      ">>>\n",
      "C        large  small\n",
      "A   B\n",
      "bar one    4.0    5.0\n",
      "      two    7.0    6.0\n",
      "foo one    4.0    1.0\n",
      "      two    NaN    6.0\n",
      "\n",
      "\n",
      "You: how is hua shi \n",
      "... ...\n",
      "Chacha: who the hell is she?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from time import sleep\n",
    "\n",
    "print(\"=============# Hi There my name is Chacha. Let's Talk #=============\")\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    \n",
    "    question = input(\"You: \")\n",
    "    \n",
    "    if question.strip().lower() in goodbye:\n",
    "        print(\"Chacha: \"+ \"Bye\")\n",
    "        break \n",
    "        \n",
    "    if  question.strip().lower() in greeting:\n",
    "        print(\"Chacha: \"+ random.choice(greeting).capitalize()+\"\\n\")\n",
    "        continue\n",
    "        \n",
    "    if question.strip().lower() in thankyou:\n",
    "        print(\"Chacha: \"+ random.choice(yourwelcome).capitalize()+\"\\n\")\n",
    "        continue\n",
    "    # NLP\n",
    "    pro_text= NLP(question)\n",
    "\n",
    "    # to find which row has intersection with the words from question you asked\n",
    "    # which means to find the who have common elements between your question and the data\n",
    "    inter_list=[]\n",
    "    for i in cleaned_questions:\n",
    "        if (set(pro_text) & set(i)):\n",
    "            inter_list.append((list(set(pro_text) & set(i)),cleaned_questions.index(i)))\n",
    "\n",
    "    # remove stop words  \n",
    "    new_inter_list=[]\n",
    "    for i in range(len(inter_list)):\n",
    "        for j in inter_list[i][0]:\n",
    "            if j not in stopwords.words('english'):\n",
    "                new_inter_list.append(inter_list[i])\n",
    "\n",
    "    # find the max length of common elements\n",
    "    lengths=[len(new_inter_list[i][0]) for i in range(len(new_inter_list)) ]\n",
    "    max_length=max(lengths)\n",
    "\n",
    "\n",
    "    if len(lengths)>0:\n",
    "        indexes=[]\n",
    "        # find all the index whose correspondiong question data have the most common elements\n",
    "        for i in range(len(new_inter_list)):\n",
    "            if len(new_inter_list[i][0])==max_length:\n",
    "                indexes.append(new_inter_list[i][1])\n",
    "    else:\n",
    "        print(\"Chacha: \"+\"Sorry, I don't know. I need to learn more!\")\n",
    "\n",
    "\n",
    "    ratios=[]\n",
    "    for i in list(set(indexes)):\n",
    "        ratio=len(pro_text)/len(questions.iloc[i])\n",
    "        ratios.append((ratio,i))\n",
    "   \n",
    "    max_ratios=max([ratios[i][0] for i in range(len(ratios))])\n",
    "\n",
    "    \n",
    "    final_indexes=[]\n",
    "    for i in range(len(ratios)):\n",
    "        if ratios[i][0]==max_ratios:\n",
    "            final_indexes.append(ratios[i][1])\n",
    "\n",
    "\n",
    "    if len(final_indexes)>0:\n",
    "        # to randomly find an answer based on the index\n",
    "        answer_index=random.choice(final_indexes)\n",
    "        \n",
    "        loading = '... ...'\n",
    "        for i in range(7):\n",
    "            print(loading[i], sep=' ', end='', flush=True); sleep(0.1)\n",
    "            \n",
    "        print(\"\\n\"+\"Chacha: \"+ answers.iloc[answer_index]+\"\\n\")\n",
    "    else:\n",
    "        print(\"Chacha: \"+\"Sorry, I don't know. I need to learn more!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
